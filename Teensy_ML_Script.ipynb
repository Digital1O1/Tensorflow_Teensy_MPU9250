{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arduino_ML_Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-",
        "colab_type": "text"
      },
      "source": [
        "## Setup Python Environment \n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "!pip install tensorflow==2.0.0-rc1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg",
        "colab_type": "text"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the files tab\n",
        "1. Drag `punch.csv` and `flex.csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9yve14gUyD",
        "colab_type": "text"
      },
      "source": [
        "# Graph Data (optional)\n",
        "\n",
        "We'll graph the input files on two separate graphs, acceleration and gyroscope, as each data set has different units and scale.\n",
        "\n",
        "---\n",
        "## Range Function\n",
        "\n",
        "* Starts at 1\n",
        "* len(df[]) = Get the number of rows: len(df), function from pandas library\n",
        "* In this case with the flex.csv, there's 395 values, so the range function will iterate through that many\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I65ukChEgyNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "filename = \"punch.csv\"\n",
        "\n",
        "df = pd.read_csv(\"/content/\" + filename)\n",
        "\n",
        "index = range(1, len(df['aX']) + 1)\n",
        "\n",
        "print(\"Lenght of ax : \", len(df['aX']))\n",
        "print(\"\\nIndex\", index)\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "plt.plot(index, df['aX'], 'g.', label='x', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['aY'], 'b.', label='y', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['aZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
        "plt.title(\"Acceleration\")\n",
        "plt.xlabel(\"Sample #\")\n",
        "plt.ylabel(\"Acceleration (G)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(index, df['gX'], 'g.', label='x', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['gY'], 'b.', label='y', linestyle='solid', marker=',')\n",
        "plt.plot(index, df['gZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
        "plt.title(\"Gyroscope\")\n",
        "plt.xlabel(\"Sample #\")\n",
        "plt.ylabel(\"Gyroscope (deg/sec)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg",
        "colab_type": "text"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3",
        "colab_type": "text"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the fully connected neural network.\n",
        "\n",
        "Update the `GESTURES` list with the gesture data you've collected in `.csv` format.\n",
        "\n",
        "---\n",
        "\n",
        "## SEED function\n",
        "\n",
        "* Sets number of values to be generated\n",
        "* np.random.seed() generates predictable random numbers\n",
        "\n",
        "---\n",
        "\n",
        "## numpy.eye()\n",
        "\n",
        "* numpy.eye() = Returns matrix that has 1's goign diagonally and 0's everywhere else\n",
        "\n",
        "* Parameters\n",
        "  numpy.eye(R,C = NONE, k = 0,dtype = type<float>, order = 'C')\n",
        "  * R = number of rows\n",
        "  * C = (Optional) number of columns | Default is M = N --> \n",
        "        M (number of columns) = N (Number of Rows)\n",
        "  * k : (int, optional, 0 by default) This is the diagonal \n",
        "      * k > 0 --> POSITIVE NUMBER --> upper diagonal\n",
        "      * k < 0 --> NEGATIVE NUMBER --> lower diagonal\n",
        "  * dtype : (optional, float by default | Data type of returned array)\n",
        "  * order : This parameter can be either C_contiguous or F_contiguous\n",
        "\n",
        "---\n",
        "\n",
        "## One Hot Encoding\n",
        "\n",
        "Reference Link : [here](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)\n",
        "\n",
        "Additional referece link : [here](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)\n",
        "\n",
        "One-hot Encoding YT [video](https://www.youtube.com/watch?v=v_4KWmkwmsU)\n",
        "\n",
        "\n",
        "ML algorithms can't work with categorical data directly and needs to be \n",
        "  converted into numbers\n",
        "  \n",
        "One hot encoding = Represent catagorical variables as binary vectors\n",
        "\n",
        "Steps to use 'One hot encoding'\n",
        "\n",
        "1. Map categorical values as integer values\n",
        "\n",
        "2. Each integer value representing a binary vector is all 0's except the index of the integer that's marked with a 1\n",
        "  * If there's a cat dog and lizard it'll look like --> [1,0,0] = cat | [0,1,0] = dog --> [0,0,1] = lizard\n",
        "  * This is used instead of string names\n",
        "    * If cat is interpreted, the vector, NOT the name is used to label it\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# the list of gestures that data is available for\n",
        "# Lists = arrays that doesn't have to have the same data, can have int,string,ect\n",
        "# Unlike Strings in python, the data in lists can be changed\n",
        "GESTURES = [\n",
        "    \"punch\",\n",
        "    \"flex\",\n",
        "    #\"fall\",\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 119\n",
        "\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "print(\"Lenght of GESTURES == NUM_GESTURES : \",NUM_GESTURES)\n",
        "\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "print(\"\\n\\n ONE_HOT FOR : \", GESTURES[0] , \" : \", ONE_HOT_ENCODED_GESTURES[0])\n",
        "print(\"\\n\\n ONE_HOT FOR : \", GESTURES[1] , \" : \", ONE_HOT_ENCODED_GESTURES[1])\n",
        "\n",
        "# Initialize inputs/output array(s)\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "# NUM_GESTURES = 2 since there's only the flex/punch CSV files\n",
        "# gesture_index is just the name for the 'FOR Loop' that's being used\n",
        "\n",
        "# ================ START of For loop ================ #\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "\n",
        "  # GESTURES = CSV files for punch and flex\n",
        "  # For loop iterates through entire CSV file and stores it in gesture\n",
        "  gesture = GESTURES[gesture_index]\n",
        "\n",
        "  print(f\"\\nProcessing index {gesture_index} for gesture '{gesture}'. \\n\\n\")\n",
        "  \n",
        "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "\n",
        "  print(\"ONE_HOT_ENCODED_GESTURES : \",output)\n",
        "  \n",
        "  # Saves contents of CSV file into df\n",
        "  df = pd.read_csv(\"/content/\" + gesture + \".csv\")\n",
        "  print(\"\\nDF : \",df)\n",
        "\n",
        "  # calculate the number of gesture recordings in the file\n",
        "  # df.shape[] = get the number of rows and columns\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "\n",
        "  print('\\n------------------------------------------------------------------\\n')\n",
        "\n",
        "  print(\"DF SHAPE : \", int(df.shape[0]))\n",
        "  \n",
        "  print(f\"\\nThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
        "\n",
        "  print('\\n------------------------------------------------------------------\\n')\n",
        "\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    for j in range(SAMPLES_PER_GESTURE):\n",
        "      index = i * SAMPLES_PER_GESTURE + j\n",
        "      # normalize the input data, between 0 to 1:\n",
        "      # - acceleration is between: -4 to +4\n",
        "      # - gyroscope is between: -2000 to +2000\n",
        "      tensor += [\n",
        "          (df['aX'][index] + 4) / 8,\n",
        "          (df['aY'][index] + 4) / 8,\n",
        "          (df['aZ'][index] + 4) / 8,\n",
        "          (df['gX'][index] + 2000) / 4000,\n",
        "          (df['gY'][index] + 2000) / 4000,\n",
        "          (df['gZ'][index] + 2000) / 4000\n",
        "          ]\n",
        "    # Takes tensor values and adds them to inputs array\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "  # ================ END of For loop ================ #\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "# inputs = normalized tensor data\n",
        "print(\"\\n---- INPUTS ----\\n\\n\", inputs)\n",
        "\n",
        "# outputs = one hot encoded data\n",
        "print(\"\\n---- OUTPUTS ----\\n\\n\", outputs)\n",
        "\n",
        "print(\"\\nData set parsing and preparation complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5_61831d5AM",
        "colab_type": "text"
      },
      "source": [
        "## Randomize and split the input and output pairs for training\n",
        "\n",
        "Randomly split input and output pairs into sets of data: 60% for training, 20% for validation, and 20% for testing.\n",
        "\n",
        "  - the training set is used to train the model\n",
        "  - the validation set is used to measure how well the model is performing during training\n",
        "  - the testing set is used to test the model after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNEmUZMeIEx",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "\n",
        "# Shuffles array along first axis of a multi-dimensional array\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# num_inputs = aX,aY,aZ,gX,gY,gZ\n",
        "print(\"Lenght of inputs : \" , num_inputs)\n",
        "print(\"\\nRandomize : \", randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "print(\"\\nRandomized Inputs : \", inputs)\n",
        "print(\"\\nRandomized Outputs : \", outputs)\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"\\nData set randomization and splitting complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9g2n41p24nR",
        "colab_type": "text"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsDkZoGOHU7u",
        "colab_type": "text"
      },
      "source": [
        "## tf.keras.layers.Dense() function notes\n",
        "\n",
        "Dense() function parameters\n",
        "* layers.Dense(units, activation = NONE)\n",
        "* Units = positive integer, dimensionality of output space\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Notes about Activation Functions\n",
        "\n",
        "#### Reference Link : [here](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/)\n",
        "\n",
        "Activation functions determines the :\n",
        "  1. Output of a deep learning model\n",
        "  2. The accuracy\n",
        "  3. Computational efficiency of training a model\n",
        "  4. Have a big effect on the N.N ability to converge and affects the \n",
        "  convergence speed\n",
        "  5. Can prevent N.N from converging in the first place\n",
        "\n",
        "Activation funcions = math equations that determine the output of a N.N\n",
        "\n",
        "  * The function is attached to each neuron in the network and determines if    a the neuron should 'fire' or not based if the neuron's input is relevant to for the model's prediction.\n",
        "\n",
        "  * They also help normalize the output of each neuron to a range between either\n",
        "  1 and 0, or -1 and 1\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Relu = Rectified Linear Unit\n",
        "\n",
        "### Reference Link : [Information about ReLU](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)\n",
        "\n",
        "### Great Youtube Video on [Activation Factors](https://www.youtube.com/watch?v=m0pIlLfpXWE)\n",
        "\n",
        "* Activation function responsible for changing the summed weighted\n",
        "   input from the node inot the activation of the node/output for that input\n",
        "\n",
        "* ReLU only takes the positive values of the input data, if data <= 0 --> it'll\n",
        "just return a 0\n",
        "\n",
        "* Relu = piecewise linear function that will output the input directly if a   positive. If not, the output will be zero\n",
        "\n",
        "* Relu is the default activation function for numerous NN since it's easy a     to train and performs better\n",
        "  \n",
        "---\n",
        "\n",
        "## Softmax\n",
        "\n",
        "* Used to impart probabilities <--- Look more into that \n",
        "* Used when there's 4 or five outputs\n",
        "* Using this A.F will get you the probability distribution of each one\n",
        "* Useful when finding the most porbable occurance/classifiction where the probability of a class is maximum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu')) \n",
        "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=1, validation_data=(inputs_validate, outputs_validate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUDPvaJE1wRE",
        "colab_type": "text"
      },
      "source": [
        "## Verify \n",
        "\n",
        "Graph the models performance vs validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxA0zCOaS35v",
        "colab_type": "text"
      },
      "source": [
        "### Graph the loss\n",
        "\n",
        "Graph the loss to see when the model stops improving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFNHXoQzmcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# increase the size of the graphs. The default size is (6,4).\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(plt.rcParams[\"figure.figsize\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG3m-VpE1zOd",
        "colab_type": "text"
      },
      "source": [
        "### Graph the loss again, skipping a bit of the start\n",
        "\n",
        "We'll graph the same data as the previous code cell, but start at index 100 so we can further zoom in once the model starts to converge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3xT7ue2zovd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# graph the loss again skipping a bit of the start\n",
        "SKIP = 100\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRjvkFQy2RgS",
        "colab_type": "text"
      },
      "source": [
        "### Graph the mean absolute error\n",
        "\n",
        "[Mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) is another metric to judge the performance of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBjCf1-2zx9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# graph of mean absolute error\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM",
        "colab_type": "text"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym",
        "colab_type": "text"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2c202a7b-7405-4e38-86da-ea208cbea377"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp03phcyj2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp03phcyj2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model is 147804 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX",
        "colab_type": "text"
      },
      "source": [
        "## Encode the Model in an Arduino Header File \n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1a308989-2a8e-48b4-fd4b-978e11103ae4"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Header file, model.h, is 911,492 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId",
        "colab_type": "text"
      },
      "source": [
        "# Classifying IMU Data\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the Arduino Nano 33 BLE Sense to classify the accelerometer and gyroscope data.\n"
      ]
    }
  ]
}